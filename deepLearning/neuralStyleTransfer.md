# 风格迁移代价神经网络

## 风格迁移代价函数：

风格迁移代价函数主要分为两部分： 内容代价函数和风格代价函数
$$J(G)=\alpha J_{content}(C,G)+\beta J_{style}(S,G)$$

这里 $C$为输入的内容图像,$S$为输入的风格图像，$G$为生成的目标图像。
只有$G$为变量值，通过不断的迭代，改进$G$中各个像素的值，使得代价函数<font color="redG">梯度下降</font>

### 内容代价函数
内容代价函数要解决的问题是，图像的内容要尽可能的保持一致。
计算方法一般是：对内容图像进行一系列的特征运算，取得一个最终的特征向量。对生成图像进行一系列相同的特征运算，得到最终的特征向量。 使得这两个特征向量直接的差距最小。 一般使用欧几里得空间计算他们的差距。
$$J_{content}(C,G)=\frac{1}{2}\begin{Vmatrix}a^{[l][C]} -a^{[l][G]}\end{Vmatrix}$$
$a^{[l][C]}$ 是内容图片计算得到的特征向量。 取神经网络的<font color="redg">前(?)</font>$l$层, 计算得到输出特征。

### 风格代价函数
风格代价函数主要利用到了一个思想：<font color="redg" size=3>特征向量的相关性越强，他们的风格越相似</font>
取 神经网络的前$l$项的特征输出，他们一般是一个矩阵$M$,计算特征相关性一般用$GM=M*M^{T}$即 特征矩阵乘以特征矩阵的转置。
<font color="redg" size=3>这是个3D矩阵，即有三个维度：长，宽，通道个数</font>
特征图和生成图的特征相关性代价函数就可以这样表示：
$$L_{GM}(S,G,l)=\frac{1}{4N_{l}^{2}M_{l}{2}} \sum_{ij}(GM[l](S)_{ij}-GM[l](G)_{ij})^{2}$$

它的意思是： 通过矩阵相乘，计算得到风格图和生成图在第$l$层的特征相关矩阵。然后矩阵中每个对应位置的<font color="redg" size=3>距离</font>, $N_{l}^{2}$表示的通道个数的平方，$M_{l}{2}$表示长*高的平方

    这仅仅是第l层的特征相关损失函数。 一般我们会使用多层进行计算。

一般需要把各个层的特征函数叠加起来。
$$L_{style}(S,G)=\sum_{0}^{L} w_{l}*L_{GM}(S,G,l)$$

$w_{l}$ 是一个超参数，主要用来表明不同层之间的权重。

至此，全部代价函数都写出来了。
